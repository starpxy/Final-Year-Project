{"author": "yunjey", "code": "import nltk\nimport pickle\nimport argparse\nfrom collections import Counter\nfrom pycocotools.coco import COCO\n\n\nclass Vocabulary(object):\n    \"\"\"Simple vocabulary wrapper.\"\"\"\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = {}\n        self.idx = 0\n\n    def add_word(self, word):\n        if not word in self.word2idx:\n            self.word2idx[word] = self.idx\n            self.idx2word[self.idx] = word\n            self.idx += 1\n\n    def __call__(self, word):\n        if not word in self.word2idx:\n            return self.word2idx['<unk>']\n        return self.word2idx[word]\n\n    def __len__(self):\n        return len(self.word2idx)\n\ndef build_vocab(json, threshold):\n    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n    coco = COCO(json)\n    counter = Counter()\n    ids = coco.anns.keys()\n    for i, id in enumerate(ids):\n        caption = str(coco.anns[id]['caption'])\n        tokens = nltk.tokenize.word_tokenize(caption.lower())\n        counter.update(tokens)\n\n        if i % 1000 == 0:\n            print(\"[%d/%d] Tokenized the captions.\" %(i, len(ids)))\n\n    \n    words = [word for word, cnt in counter.items() if cnt >= threshold]\n\n    \n    vocab = Vocabulary()\n    vocab.add_word('<pad>')\n    vocab.add_word('<start>')\n    vocab.add_word('<end>')\n    vocab.add_word('<unk>')\n\n    \n    for i, word in enumerate(words):\n        vocab.add_word(word)\n    return vocab\n\ndef main(args):\n    vocab = build_vocab(json=args.caption_path,\n                        threshold=args.threshold)\n    vocab_path = args.vocab_path\n    with open(vocab_path, 'wb') as f:\n        pickle.dump(vocab, f)\n    print(\"Total vocabulary size: %d\" %len(vocab))\n    print(\"Saved the vocabulary wrapper to '%s'\" %vocab_path)\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--caption_path', type=str, \n                        default='/usr/share/mscoco/annotations/captions_train2014.json', \n                        help='path for train annotation file')\n    parser.add_argument('--vocab_path', type=str, default='./data/vocab.pkl', \n                        help='path for saving vocabulary wrapper')\n    parser.add_argument('--threshold', type=int, default=4, \n                        help='minimum word count threshold')\n    args = parser.parse_args()\n    main(args)", "comments": "   simple vocabulary wrapper         def   init  (self)          self word2idx              self idx2word              self idx   0      def add word(self  word)          word self word2idx              self word2idx word    self idx             self idx2word self idx    word             self idx    1      def   call  (self  word)          word self word2idx              return self word2idx   unk            return self word2idx word       def   len  (self)          return len(self word2idx)  def build vocab(json  threshold)         build simple vocabulary wrapper        if word frequency less  threshold   word discarded     creates vocab wrapper add special tokens     adds words vocabulary  ", "content": "import nltk\nimport pickle\nimport argparse\nfrom collections import Counter\nfrom pycocotools.coco import COCO\n\n\nclass Vocabulary(object):\n    \"\"\"Simple vocabulary wrapper.\"\"\"\n    def __init__(self):\n        self.word2idx = {}\n        self.idx2word = {}\n        self.idx = 0\n\n    def add_word(self, word):\n        if not word in self.word2idx:\n            self.word2idx[word] = self.idx\n            self.idx2word[self.idx] = word\n            self.idx += 1\n\n    def __call__(self, word):\n        if not word in self.word2idx:\n            return self.word2idx['<unk>']\n        return self.word2idx[word]\n\n    def __len__(self):\n        return len(self.word2idx)\n\ndef build_vocab(json, threshold):\n    \"\"\"Build a simple vocabulary wrapper.\"\"\"\n    coco = COCO(json)\n    counter = Counter()\n    ids = coco.anns.keys()\n    for i, id in enumerate(ids):\n        caption = str(coco.anns[id]['caption'])\n        tokens = nltk.tokenize.word_tokenize(caption.lower())\n        counter.update(tokens)\n\n        if i % 1000 == 0:\n            print(\"[%d/%d] Tokenized the captions.\" %(i, len(ids)))\n\n    # If the word frequency is less than 'threshold', then the word is discarded.\n    words = [word for word, cnt in counter.items() if cnt >= threshold]\n\n    # Creates a vocab wrapper and add some special tokens.\n    vocab = Vocabulary()\n    vocab.add_word('<pad>')\n    vocab.add_word('<start>')\n    vocab.add_word('<end>')\n    vocab.add_word('<unk>')\n\n    # Adds the words to the vocabulary.\n    for i, word in enumerate(words):\n        vocab.add_word(word)\n    return vocab\n\ndef main(args):\n    vocab = build_vocab(json=args.caption_path,\n                        threshold=args.threshold)\n    vocab_path = args.vocab_path\n    with open(vocab_path, 'wb') as f:\n        pickle.dump(vocab, f)\n    print(\"Total vocabulary size: %d\" %len(vocab))\n    print(\"Saved the vocabulary wrapper to '%s'\" %vocab_path)\n\n\nif __name__ == '__main__':\n    parser = argparse.ArgumentParser()\n    parser.add_argument('--caption_path', type=str, \n                        default='/usr/share/mscoco/annotations/captions_train2014.json', \n                        help='path for train annotation file')\n    parser.add_argument('--vocab_path', type=str, default='./data/vocab.pkl', \n                        help='path for saving vocabulary wrapper')\n    parser.add_argument('--threshold', type=int, default=4, \n                        help='minimum word count threshold')\n    args = parser.parse_args()\n    main(args)", "description": "PyTorch Tutorial for Deep Learning Researchers", "file_name": "build_vocab.py", "id": "ae04ea4e1a5ce005424c454dba71401c", "language": "Python", "project_name": "pytorch-tutorial", "quality": "", "save_path": "/home/ubuntu/test_files/clean/python/yunjey-pytorch-tutorial/yunjey-pytorch-tutorial-6c785eb/tutorials/03-advanced/image_captioning/build_vocab.py", "save_time": "", "source": "", "update_at": "2018-03-18T14:24:45Z", "url": "https://github.com/yunjey/pytorch-tutorial", "wiki": true}